# Contributing to ethskills

PRs from humans and agents are welcome. Before submitting, understand the bar:

## The Rule

**Every line must either fill a verified LLM blind spot OR be something the agent needs to teach the human.**

If a stock LLM already knows something *and* the human doesn't need to hear it, it doesn't belong here. But some content exists because the agent is a teacher â€” the human needs to learn about gas costs, security patterns, or why Ethereum matters, and the agent needs accurate material to teach from. Both are valid reasons for a line to exist.

## How to Evaluate a Change

Before adding or modifying content, run the triage process:

1. **Spawn a fresh LLM** â€” no tools, no skills, no web access. Pure training data.
2. **Give it a realistic task** that exercises the content you're proposing. Don't ask "do you know X?" â€” ask it to *build something* and examine what it produces.
3. **Classify each item** in your proposed change:
   - ðŸ”´ **LLM blind spot** â€” consistently gets this wrong â†’ **keep**
   - ðŸŸ£ **Human needs to learn this** â€” the agent knows it, but needs to teach it accurately â†’ **keep**
   - ðŸŸ¡ **Knows but skips** â€” knows the concept, won't do it unprompted â†’ **compress to one line**
   - ðŸŸ¢ **Does this naturally** â€” any competent model does this already AND human doesn't need teaching â†’ **cut**

Full methodology with worked examples: [research/triage-methodology.md](https://github.com/austintgriffith/ethskills-research/blob/master/research/triage-methodology.md)

## Anti-Patterns

- **Don't trust intuition.** "I think agents get this wrong" is not evidence. Run the test.
- **Don't ask leading questions.** The LLM will say "yes I know that." Make it *demonstrate* knowledge by building.
- **Don't keep content because it's correct.** Correct â‰  necessary. A lot of correct information is already in training data.
- **Don't pad skills with training-data-tier knowledge.** A 95-line skill that's all blind spots is more effective than a 205-line skill where half is noise.

## PR Checklist

- [ ] Ran a baseline test against a stock LLM (no tools/skills)
- [ ] Every item classified as ðŸ”´, ðŸŸ¡, or ðŸŸ¢
- [ ] ðŸŸ¢ items removed
- [ ] ðŸŸ¡ items compressed
- [ ] Content verified against onchain reality (not LLM-generated "facts")
